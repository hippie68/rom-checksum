#!/bin/bash

# This script calculates SHA-1 checksums for ROM files and ROM files inside
# archives, ignoring ROM headers. Which is particularly useful to check for
# romhack compatibility.
# Currently only NES headers are ignored. Please let me know if there is demand
# for more headered file types.
# The script requires GNU coreutils and at least Bash 4.4.
# For archive support, the following programs are required:
# - unzip for .zip files
# - gunzip for .gz files
# - 7za for .7z files
# Project homepage: https://github.com/hippie68/rom-sha1sum

MAX_DECOMPRESSION_RECURSION_LVL=1 # Increase to parse deeply nested archives.
FILE_EXTENSIONS=(3ds gb gba gbc gcm gcz gen gg md n64 ngc ngp nds nes nez nsp pce sfc smc smd srl v64 vb vpk wbfs ws wsc xci xiso z64 zip gz 7z) # Note: additional archives must be handled in process_file().
declare FILE_EXT_REGEX

# $1: name of an array containing file extensions (without dots)
create_file_ext_regex() {
    local -n extensions=$1
    IFS=\| FILE_EXT_REGEX="\\.(${extensions[*]})\$"
}

print_usage() {
    cat <<EOF
Usage: $(basename "$0") FILE/DIRECTORY [...]

Options:
  -e LIST  Only process files that have one the file extensions specified
           without dots in comma-separated argument LIST.
  -r       Parse directories recursively.
EOF
}

# $1: string, $2: delimiter character, $3: the output array's name
split_string() {
    local -n array=$3
    readarray -t -d "$2" array <<< "$1"
    array[-1]=${array[-1]::-1}
}

parse_args() {
    while getopts e:r opt; do
        case $opt in
            r) opt_recursive=1;;
            e)
                split_string "$OPTARG" , opt_extensions
                create_file_ext_regex opt_extensions
                ;;
            *) print_usage; exit 1;;
        esac
    done
}

get_magic() {
    head --bytes=4 "$1" | tr -d '\000'
}

# $1: filename, $2: offset, $3: variable name
sha1sum_to_var() {
    local -n sha1=$3
    if [[ $2 -ne 0 ]]; then
        sha1=$(tail --bytes=+$(("$2" + 1)) "$1" | sha1sum)
    else
        sha1=$(sha1sum "$1")
    fi
    sha1=${sha1:0:40}
}

# $1: checksum, $2: filename, $3: suffix, $4: archive chain
print_checksum() {
    echo -n "$1  "
    echo -n "$2"
    [[ $3 ]] && echo -en " \033[1;32m$3\033[0m"
    [[ $4 ]] && echo -en " \033[1;30m$4\033[0m"
    echo
}

# Do sha1sum for file $1, but skip $2 bytes. $3: archive name
sha1sum_skip_n() {
    local sha1_full
    sha1sum_to_var "$1" 0 sha1_full
    local filename
    filename=$(basename "$1")
    if [[ $2 -gt 0 ]]; then
        local sha1_without_header
        sha1sum_to_var "$1" "$2" sha1_without_header
        print_checksum "$sha1_without_header" "$filename" "[-H]" "$3"
        print_checksum "$sha1_full"  "$filename" "[+H]" "$3"
    else
        print_checksum "$sha1_full" "$filename" "" "$3"
    fi
}

warning() {
    echo -e "\033[1;33mWARNING: \033[0m$1" >&2
}

error() {
    echo -e "\033[1;31mERROR: \033[0m$1" >&2
}

# $1: filename, $2: recursion level
max_recursion_reached() {
    if [[ $2 -gt $MAX_DECOMPRESSION_RECURSION_LVL ]]; then
        error "Ignoring nested archive file (too many recursions): \"$1\""
        return 0
    fi
    return 1
}

create_archive_wildcards() {
    local -a extensions
    if [[ -v opt_extensions ]]; then
        extensions=$opt_extensions
    else
        extensions=("${FILE_EXTENSIONS[@]}")
    fi

    declare -ag ARCHIVE_FILE_WILDCARDS
    # ARCHIVE_FILE_WILDCARDS=("${FILE_EXTENSIONS[@]}")
    ARCHIVE_FILE_WILDCARDS=("${extensions[@]}")
    for ((i = 0; i < ${#ARCHIVE_FILE_WILDCARDS[@]}; i++)) {
        ARCHIVE_FILE_WILDCARDS[i]="*?.${ARCHIVE_FILE_WILDCARDS[$i]}"
    }
}

# $1: current archive chain, $2: nested archive
update_archive_chain() {
    local -n chain=$1
    if [[ $chain ]]; then
        chain="< $(basename "$2") $chain"
    else
        chain="< $2"
    fi
}

# $1: filename, $2: recursion level, $3: archive chain
process_file() {
    local archive_chain=$3
    local magic
    if ! magic=$(get_magic "$1"); then
        error "Could not read magic number from file \"$1\""
        exit 1
    fi

    # Process archive file
    if [[ $1 =~ .*\.(zip|gz|7z) ]]; then
        max_recursion_reached "$1" "$2" && return

        case $1 in
            *.zip)
                if [[ $magic != $'PK\x03\x04' ]]; then
                    warning "Not a ZIP file: \"$1\""
                    return
                fi

                [[ ! -v ARCHIVE_FILE_WILDCARDS ]] && create_archive_wildcards
                local tmp_dir
                tmp_dir=$(mktemp --directory) || exit 1
                unzip -d "$tmp_dir" "$1" "${ARCHIVE_FILE_WILDCARDS[@]}" &> /dev/null
                local ret=$?
                if [[ $ret -eq 0 || $ret -eq 11 ]]; then
                    update_archive_chain archive_chain "$1"
                    readarray -d '' < <(find "$tmp_dir" -type f -print0 2> /dev/null)
                    for file in "${MAPFILE[@]}"; do
                        process_file "$file" $(($2 + 1)) "$archive_chain"
                    done
                else
                    error "Could not extract ZIP file \"$1\""
                fi
                rm -r "$tmp_dir" || exit 1
                ;;
            *.gz)
                if [[ $1 == *.tar.gz ]]; then
                    warning "Ignoring file \"$1\" (.tar.gz not supported)"
                    return
                fi
                if [[ $magic != $'\x1f\x8b'* ]]; then
                    warning "Not a gzip file: \"$1\""
                    return
                fi

                local tmp_dir
                tmp_dir=$(mktemp --directory) || exit 1
                tmp_file="$tmp_dir/$(basename "${1%.gz}")"
                if gunzip --to-stdout "$1" > "$tmp_file"; then
                    update_archive_chain archive_chain "$1"
                    process_file "$tmp_file" $(($2 + 1)) "$archive_chain"
                else
                    error "Could not extract gzip file \"$1\""
                fi
                rm -r "$tmp_dir" || exit 1
                ;;
            *.7z)
                if [[ $magic != $'7z\xbc\xaf' ]]; then
                    warning "Not a 7-Zip file: \"$1\""
                    return
                fi

                [[ ! -v ARCHIVE_FILE_WILDCARDS ]] && create_archive_wildcards
                local tmp_dir
                tmp_dir=$(mktemp --directory) || exit 1
                if 7za x -o"$tmp_dir" "$1" "${ARCHIVE_FILE_WILDCARDS[@]}" > /dev/null; then
                    update_archive_chain archive_chain "$1"
                    readarray -d '' < <(find "$tmp_dir" -type f -print0 2> /dev/null)
                    for file in "${MAPFILE[@]}"; do
                        process_file "$file" $(($2 + 1)) "$archive_chain"
                    done
                else
                    error "Could not extract 7-Zip file \"$1\""
                fi
                rm -r "$tmp_dir" || exit 1
                ;;
        esac
        return
    fi

    # Process non-archive file
    case $magic in
        $'NES\x1a')
            sha1sum_skip_n "$1" 16 "$archive_chain"
            ;;
        *)
            shopt -s nocasematch
            if [[ $1 =~ $FILE_EXT_REGEX ]]; then
                [[ $1 == *.md ]] && [[ $(file "$1") == *text* ]] && return
                sha1sum_skip_n "$1" 0 "$3"
            else
                error "Unknown file extension: \"$1\""
            fi
            shopt -u nocasematch
            ;;
    esac
}

parse_file() {
    if [[ -d $1 ]]; then
        local maxdepth
        [[ -v opt_recursive ]] || maxdepth=(-maxdepth 1)
        readarray -d '' files < <(find "$1" "${maxdepth[@]}" -type f -regextype posix-extended -regex ".*$FILE_EXT_REGEX" -print0 2> /dev/null)
        for f in "${files[@]}"; do
            parse_file "$f"
        done
    elif [[ ! -f $1 ]]; then
        error "Not a file: \"$1\""
    else
        process_file "$1" 0
    fi
}

# ------------------------------------------------------------------------------

parse_args "$@"
shift $((OPTIND - 1))
if [[ ! $1 ]]; then
    print_usage
    exit 0
fi
[[ ! -v FILE_EXT_REGEX ]] && create_file_ext_regex FILE_EXTENSIONS

for file in "$@"; do
    parse_file "$file"
done
